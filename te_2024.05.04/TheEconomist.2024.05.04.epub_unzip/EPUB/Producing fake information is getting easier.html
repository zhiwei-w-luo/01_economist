<?xml version='1.0' encoding='utf-8'?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" epub:prefix="z3998: http://www.daisy.org/z3998/2012/vocab/structure/#" lang="en" xml:lang="en">
  <head>
    <title>Producing fake information is getting easier</title>
    <link href="static_styles/default_styles.css" rel="stylesheet" type="text/css"/>
  </head>
  <body><h4 class="te_fly_title">Generation confusion</h4><br/><h1 class="te_article_title">Producing fake information is getting easier</h1><h3 class="te_article_rubric">But that’s not the whole story, when it comes to AI</h3><h3 class="te_article_datePublished">May 01th 2024</h3><br/><div class="head_image_div"><img src="static_images/e75c758f1318eac8e36203e081102778.jpg" alt="" class="te_head_image"/></div><p><span>When it </span>comes to disinformation, “social media took the cost of distribution to zero, and generative <small>AI</small> takes the cost of generation to zero,” says Renée DiResta of the Stanford Internet Observatory. Large language models such as <small>GPT</small>-4 make it easy to produce <a href="https://www.economist.com/science-and-technology/2024/05/01/disinformation-is-on-the-rise-how-does-it-work">misleading news articles</a> or social-media posts in huge quantities. </p><p>And <small>AI</small> can produce more than text. Cloning a voice using <small>AI</small> used to require minutes, or even hours, of sample audio. Last year, however, researchers at Microsoft unveiled <small>VALL-E</small>, an <small>AI</small> model that is able to clone a person’s voice from just a three-second clip of them speaking, and make it say any given text. </p><aside><p><b>More from this package</b></p><ul><li><a href="https://www.economist.com/leaders/2024/05/02/how-disinformation-works-and-how-to-counter-it">How disinformation works—and how to counter it</a></li><li><a href="https://www.economist.com/science-and-technology/2024/05/01/disinformation-is-on-the-rise-how-does-it-work">Disinformation is on the rise. How does it work?</a></li><li><a href="https://www.economist.com/interactive/science-and-technology/2024/05/01/the-truth-behind-olena-zelenskas-cartier-haul">The anatomy of a disinformation campaign</a></li><li><a href="https://www.economist.com/science-and-technology/2024/05/01/fighting-disinformation-gets-harder-just-when-it-matters-most">Fighting disinformation gets harder, just when it matters most</a></li></ul></aside><p>Open<small>AI</small>, the American company behind <small>GPT</small>-4, has developed a similar tool, Voice Engine, which can convincingly clone any voice from a 15-second clip. It has not yet released it, recognising “serious risks, which are especially top of mind in an election year”.</p><p>Similarly, Sora, from Open<small>AI</small>, can produce surprisingly realistic synthetic videos, in response to text prompts, of up to a minute in length. Open<small>AI</small> has yet to release Sora to the public, partly on the ground that it could be used to create disinformation. As well as providing new ways to discredit or misrepresent politicians, <small>AI</small> tools also raise the spectre of personalised disinformation, generated to appeal to small groups (think soccer moms in a specific town). It may even be possible to “microtarget” individuals with disinformation, based on knowledge of their preferences, biases and concerns.</p><p>Though all of this is worrying, it is worth remembering that not all aspects of the technology are negative. <small>AI</small>, it turns out, can be used for <a href="https://www.economist.com/science-and-technology/2024/05/01/disinformation-is-on-the-rise-how-does-it-work">fighting disinformation</a> as well as producing it. <span class="span_ufinish">■</span></p><p class="link_navbar">This article was downloaded by <a href="https://z-lib.io" class="producer_link">zlibrary</a> from <a href="https://www.economist.com/science-and-technology/2024/05/01/producing-fake-information-is-getting-easier" class="origin_link">https://www.economist.com/science-and-technology/2024/05/01/producing-fake-information-is-getting-easier</a> </p>
</body>
</html>
